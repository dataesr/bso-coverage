{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSFM examples\n",
    "# With DOI\n",
    "# Without DOI\n",
    "# OpenAlex examples\n",
    "# With DOI : https://api.openalex.org/works/https://doi.org/10.35562/arabesques.3084\n",
    "# Without DOI : https://api.openalex.org/works/W3204678669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import re\n",
    "import requests\n",
    "from retry import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "FOSM_BASE_URL = \"https://cluster.elasticsearch.dataesr.ovh\"\n",
    "FOSM_INDEX = \"bso-publications-20230728\"\n",
    "FOSM_LIMIT = 0  # Set to 0 for no limit\n",
    "FOSM_PAGE_SIZE = 10000  # Maximum is 10000\n",
    "MONGO_DB = \"bsocoverage\"\n",
    "MONGO_COLLECTION = \"publications\"\n",
    "OA_LIMIT = 0  # Set to 0 for no limit\n",
    "OA_PAGE_SIZE = 200  # Maximum is 200\n",
    "\n",
    "# Access the environment variables from the .env file\n",
    "FOSM_AUTHORIZATION=os.getenv(\"FOSM_AUTHORIZATION\")\n",
    "OA_API_KEY=os.getenv(\"OA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_database = pymongo.MongoClient()[MONGO_DB]\n",
    "mongo_collection = mongo_database[MONGO_COLLECTION]\n",
    "# mongo_collection.drop()\n",
    "# mongo_collection.create_index([(\"id\", pymongo.ASCENDING)], unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of publications in French OSM\n",
    "json = {\n",
    "  \"query\": { \"bool\": { \"must\": [\n",
    "    { \"range\": { \"year\": { \"gte\": 2013, \"lte\": 2021 } } },\n",
    "    { \"term\": { \"bso_country_corrected\": \"fr\" } },\n",
    "    { \"terms\": { \"genre.keyword\": [ \"journal-article\", \"proceedings\", \"book-chapter\", \"book\", \"preprint\" ] } },\n",
    "  ] } },\n",
    "}\n",
    "r = requests.get(\"/\".join([FOSM_BASE_URL, FOSM_INDEX, \"_count\"]),\n",
    "                 headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"}, json=json)\n",
    "fosm_total_count = r.json().get(\"count\")\n",
    "fosm_total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(Exception, tries=5, delay=10)\n",
    "def get_fosm_publications(pit, total_results_count, search_after=None):\n",
    "    print(f\"{pit}, {total_results_count}, {search_after}\")\n",
    "    json = {\n",
    "        \"pit\": {\"id\":  pit, \"keep_alive\": \"1m\"},\n",
    "        \"query\": { \"bool\": { \"must\": [\n",
    "            { \"range\": { \"year\": { \"gte\": 2013, \"lte\": 2021 } } },\n",
    "            { \"term\": { \"bso_country_corrected\": \"fr\" } },\n",
    "            { \"terms\": { \"genre.keyword\": [ \"journal-article\", \"proceedings\", \"book-chapter\", \"book\", \"preprint\" ] } },\n",
    "        ] } },\n",
    "        \"size\": FOSM_PAGE_SIZE,\n",
    "        \"sort\": [\"_doc\"],\n",
    "    }\n",
    "    if search_after:\n",
    "        json[\"search_after\"] = search_after\n",
    "        json[\"track_total_hits\"] = False\n",
    "    r = requests.get(\"/\".join([FOSM_BASE_URL, \"_search\"]),\n",
    "                     headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"}, json=json)\n",
    "    response = r.json()\n",
    "    results = response.get(\"hits\").get(\"hits\")\n",
    "    actions = []\n",
    "    for publication in results:\n",
    "        doi = publication.get(\"_source\", {}).get(\"doi\")\n",
    "        hal_id = publication.get(\"_source\", {}).get(\"hal_id\")\n",
    "        id = doi if doi else hal_id\n",
    "        id = id.lower()\n",
    "        publication = {\n",
    "            \"all_ids\": publication.get(\"_source\").get(\"external_ids\"),\n",
    "            \"id\": id,\n",
    "            \"is_in_fosm\": True,\n",
    "            \"year_fosm\": publication.get(\"_source\").get(\"year\")\n",
    "        }\n",
    "        if doi:\n",
    "            publication[\"doi\"] = doi\n",
    "        if hal_id:\n",
    "            publication[\"hal_id\"] = hal_id\n",
    "        actions.append(pymongo.UpdateOne(\n",
    "            {\"id\": id}, {\"$set\": publication}, upsert=True))\n",
    "    if len(actions) > 0:\n",
    "        mongo_collection.bulk_write(actions, ordered=False)\n",
    "    total_results_count += len(results)\n",
    "    search_after = results[len(results) - 1].get(\"sort\")\n",
    "    next_pit = response.get(\"pit_id\")\n",
    "    del json\n",
    "    del r\n",
    "    del response\n",
    "    del results\n",
    "    del actions\n",
    "    print('{:.0f} %'.format((total_results_count / fosm_total_count) * 100))\n",
    "    if FOSM_LIMIT == 0 or total_results_count < FOSM_LIMIT:\n",
    "        return get_fosm_publications(next_pit, total_results_count, search_after)\n",
    "    else:\n",
    "        return total_results_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all documents from FOSM only, in Mongo\n",
    "# delete = mongo_collection.delete_many({ \"is_in_fosm\": \"true\", \"is_in_openalex\": { \"$exists\": False } })\n",
    "# print(delete.deleted_count, \" documents deleted\")\n",
    "# Delete \"is_in_fosm\" field for all documents in Mongo\n",
    "# updated = mongo_collection.update_many({}, { \"$unset\": { \"is_in_fosm\": 1 } } , True)\n",
    "# print(updated.modified_count, \" documents modified\")\n",
    "# Get Point In Time\n",
    "r = requests.post(\"/\".join([FOSM_BASE_URL, FOSM_INDEX, \"_pit?keep_alive=1m\"]),\n",
    "                  headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"})\n",
    "pit = r.json().get(\"id\")\n",
    "# Collect all publications with DOI in French OSM\n",
    "fosm_publications = get_fosm_publications(pit, 0)\n",
    "print(fosm_publications)\n",
    "# Delete Point In Time\n",
    "r = requests.delete(\"/\".join([FOSM_BASE_URL, \"_pit\"]), headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"}, json={\"id\": pit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of French publications in OpenAlex\n",
    "r = requests.get(\n",
    "    f\"https://api.openalex.org/works?filter=institutions.country_code:FR,is_paratext:false,publication_year:2013-2021&api_key={OA_API_KEY}\")\n",
    "openalex_total_count = r.json().get(\"meta\").get(\"count\")\n",
    "print(openalex_total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(Exception, tries=5, delay=30)\n",
    "def get_openalex_publications(cursor, total_results_count):\n",
    "    print(f\"\\\"{cursor}\\\", {total_results_count}\")\n",
    "    r = requests.get(\n",
    "        f\"https://api.openalex.org/works?filter=institutions.country_code:FR,is_paratext:false,publication_year:2013-2021&per-page={OA_PAGE_SIZE}&api_key={OA_API_KEY}&cursor={cursor}\")\n",
    "    response = r.json()\n",
    "    results = response.get(\"results\")\n",
    "    actions = []\n",
    "    for publication in results:\n",
    "        open_alex_id = publication.get(\"id\")\n",
    "        doi = False\n",
    "        if publication.get(\"doi\"):\n",
    "            doi = publication.get(\"doi\", \"\").replace(\"https://doi.org/\", \"\")\n",
    "        hal_landing_page_urls = [location.get(\"landing_page_url\") for location in response.get(\"locations\", []) if re.match(\"^https:\\/\\/hal\\.(science|archives-ouvertes.fr)/(hal-\\d*)\", location.get(\"landing_page_url\", \"\"))]\n",
    "        hal_ids_uniq = list(set([hal_landing_page_url.split('/')[3] for hal_landing_page_url in hal_landing_page_urls]))\n",
    "        if len(hal_ids_uniq) > 1:\n",
    "            print(f\"More than one hal_id in OpenAlex work : {open_alex_id}\")\n",
    "            hal_id = False\n",
    "        else:\n",
    "            hal_id = hal_ids_uniq[0] if len(hal_ids_uniq) == 1 else False\n",
    "        id = doi if doi else hal_id if hal_id else open_alex_id\n",
    "        id = id.lower()\n",
    "        if id:\n",
    "            all_ids = [{\"id_type\": k, \"id_value\": v} for k, v in publication.get(\"ids\").items()]\n",
    "            if open_alex_id and len([id for id in all_ids if id.get(\"id_type\") == \"openalex\"]) == 0:\n",
    "                all_ids.append({\"id_type\": \"openalex\", \"id_value\": open_alex_id})\n",
    "            if doi and len([id for id in all_ids if id.get(\"id_type\") == \"doi\"]) == 0:\n",
    "                all_ids.append({\"id_type\": \"doi\", \"id_value\": doi})\n",
    "            if hal_id and len([id for id in all_ids if id.get(\"id_type\") == \"hal_id\"]) == 0:\n",
    "                all_ids.append({\"id_type\": \"hal_id\", \"id_value\": hal_id})\n",
    "            publication = {\n",
    "                \"all_ids\": all_ids,\n",
    "                \"id\": id,\n",
    "                \"is_in_openalex\": True,\n",
    "                \"year_openalex\": publication.get(\"publication_year\")\n",
    "            }\n",
    "            actions.append(pymongo.UpdateOne(\n",
    "                {\"id\": id}, {\"$set\": publication}, upsert=True))\n",
    "    if len(actions) > 0:\n",
    "        mongo_collection.bulk_write(actions, ordered=False)\n",
    "    results_count = len(results)\n",
    "    total_results_count += results_count\n",
    "    next_cursor = response.get(\"meta\").get(\"next_cursor\")\n",
    "    del actions\n",
    "    del r\n",
    "    del response\n",
    "    del results\n",
    "    print('{:.0f} %'.format((total_results_count / openalex_total_count) * 100))\n",
    "    if next_cursor is not None and results_count > 0 and (OA_LIMIT == 0 or len(total_results_count) < OA_LIMIT):\n",
    "        return get_openalex_publications(next_cursor, total_results_count)\n",
    "    else:\n",
    "        return total_results_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all documents from OpenAlex only, in Mongo\n",
    "# delete = mongo_collection.delete_many({ \"is_in_openalex\": \"true\", \"is_in_fosm\": { \"$exists\": False } })\n",
    "# print(delete.deleted_count, \" documents deleted\")\n",
    "# Delete \"is_in_openalex\" field for all documents in Mongo\n",
    "# updated = mongo_collection.update_many({}, { \"$unset\": { \"is_in_openalex\": 1 } } , { \"multi\": True })\n",
    "# print(updated.updated_count, \" documents updated\")\n",
    "# Collect all French publications in OpenAlex\n",
    "# openalex_publications = get_openalex_publications(\"*\", 0)\n",
    "openalex_publications = get_openalex_publications(\"IlswLCAnaHR0cHM6Ly9vcGVuYWxleC5vcmcvVzQzMTgzMTg0MTEnXSI=\", 1813200)\n",
    "print(openalex_publications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the whole database\n",
    "# mongodump --uri=\"mongodb://localhost:27017\" --archive=bsocoverage.20230917.gz --gzip --db=bsocoverage\n",
    "# Restore a gzipped database\n",
    "# mongorestore --uri=\"mongodb://localhost:27017\" --archive=bsocoverage.20230917.gz --gzip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
