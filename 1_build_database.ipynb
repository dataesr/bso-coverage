{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import re\n",
    "import requests\n",
    "from retry import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "FOSM_BASE_URL=\"https://cluster.elasticsearch.dataesr.ovh\"\n",
    "FOSM_INDEX=\"bso-publications\"\n",
    "FOSM_LIMIT=0  # Set to 0 for no limit\n",
    "FOSM_PAGE_SIZE=10000  # Maximum is 10000\n",
    "FOSM_PIT_KEEP_ALIVE=\"5m\"\n",
    "MONGO_CHUNK_SIZE=500\n",
    "MONGO_COLLECTION=\"publications\"\n",
    "MONGO_DB=\"bsocoverage\"\n",
    "OA_LIMIT=0  # Set to 0 for no limit\n",
    "OA_PAGE_SIZE=200  # Maximum is 200\n",
    "\n",
    "# Access the environment variables from the .env file\n",
    "FOSM_AUTHORIZATION=os.getenv(\"FOSM_AUTHORIZATION\")\n",
    "MONGO_URI=os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017/\")\n",
    "OA_API_KEY=os.getenv(\"OA_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_database = pymongo.MongoClient(MONGO_URI)[MONGO_DB]\n",
    "mongo_collection = mongo_database[MONGO_COLLECTION]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import FOSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of publications in French OSM\n",
    "json = {\n",
    "  \"query\": { \"bool\": { \"must\": [\n",
    "    { \"range\": { \"year\": { \"gte\": 2013, \"lte\": 2021 } } },\n",
    "    { \"term\": { \"bso_country_corrected\": \"fr\" } },\n",
    "    { \"terms\": { \"genre.keyword\": [ \"journal-article\", \"proceedings\", \"book-chapter\", \"book\", \"preprint\" ] } },\n",
    "  ] } },\n",
    "}\n",
    "r = requests.get(\"/\".join([FOSM_BASE_URL, FOSM_INDEX, \"_count\"]), headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"}, json=json)\n",
    "fosm_total_count = r.json().get(\"count\")\n",
    "print(fosm_total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(Exception, tries=5, delay=10)\n",
    "def get_fosm_publications(pit, total_results_count=0, search_after=None):\n",
    "    try:\n",
    "        print(f\"\\\"{pit}\\\", {total_results_count}, {search_after}\")\n",
    "        json = {\n",
    "            \"pit\": {\"id\":  pit, \"keep_alive\": FOSM_PIT_KEEP_ALIVE},\n",
    "            \"query\": { \"bool\": { \"must\": [\n",
    "                { \"range\": { \"year\": { \"gte\": 2013, \"lte\": 2021 } } },\n",
    "                { \"term\": { \"bso_country_corrected\": \"fr\" } },\n",
    "                { \"terms\": { \"genre.keyword\": [ \"journal-article\", \"proceedings\", \"book-chapter\", \"book\", \"preprint\" ] } },\n",
    "            ] } },\n",
    "            \"size\": FOSM_PAGE_SIZE,\n",
    "            \"sort\": [\"_shard_doc\"],\n",
    "        }\n",
    "        if search_after:\n",
    "            json[\"search_after\"] = search_after\n",
    "            json[\"track_total_hits\"] = False\n",
    "        r = requests.get(\"/\".join([FOSM_BASE_URL, \"_search\"]),\n",
    "                        headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"}, json=json)\n",
    "        response = r.json()\n",
    "        results = response.get(\"hits\").get(\"hits\")\n",
    "        actions = []\n",
    "        for publication in results:\n",
    "            doi = publication.get(\"_source\", {}).get(\"doi\")\n",
    "            hal_id = publication.get(\"_source\", {}).get(\"hal_id\")\n",
    "            id = doi if doi else hal_id\n",
    "            id = id.lower()\n",
    "            publication = {\n",
    "                \"all_ids\": publication.get(\"_source\").get(\"external_ids\"),\n",
    "                \"id\": id,\n",
    "                \"is_in_fosm\": True,\n",
    "                \"fosm\": publication.get(\"_source\"),\n",
    "            }\n",
    "            if doi:\n",
    "                publication[\"doi\"] = doi\n",
    "            if hal_id:\n",
    "                publication[\"hal_id\"] = hal_id\n",
    "            actions.append(pymongo.UpdateOne(\n",
    "                {\"id\": id}, {\"$set\": publication}, upsert=True))\n",
    "        if len(actions) > 0:\n",
    "            mongo_collection.bulk_write(actions, ordered=False)\n",
    "        results_count = len(results)\n",
    "        total_results_count += results_count\n",
    "        last_result = results[results_count - 1]\n",
    "        next_pit = response.get(\"pit_id\")\n",
    "        del json\n",
    "        del r\n",
    "        del response\n",
    "        del results\n",
    "        del actions\n",
    "        print('{:.0f} %'.format((total_results_count / fosm_total_count) * 100))\n",
    "        if results_count > 0 and (FOSM_LIMIT == 0 or total_results_count < FOSM_LIMIT):\n",
    "            search_after = last_result.get(\"sort\")\n",
    "            return get_fosm_publications(next_pit, total_results_count, search_after)\n",
    "        else:\n",
    "            return total_results_count\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Point In Time\n",
    "r = requests.post(\"/\".join([FOSM_BASE_URL, FOSM_INDEX, f\"_pit?keep_alive={FOSM_PIT_KEEP_ALIVE}\"]), headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"})\n",
    "pit = r.json().get(\"id\")\n",
    "# Collect all publications with DOI in French OSM\n",
    "fosm_publications = get_fosm_publications(pit)\n",
    "print(fosm_publications)\n",
    "# Delete Point In Time\n",
    "r = requests.delete(\"/\".join([FOSM_BASE_URL, \"_pit\"]), headers={\"Authorization\": f\"Basic {FOSM_AUTHORIZATION}\"}, json={\"id\": pit})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of French publications in OpenAlex\n",
    "r = requests.get(\n",
    "    f\"https://api.openalex.org/works?filter=institutions.country_code:FR,is_paratext:false,publication_year:2013-2021&api_key={OA_API_KEY}\")\n",
    "openalex_total_count = r.json().get(\"meta\").get(\"count\")\n",
    "print(openalex_total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(Exception, tries=5, delay=30)\n",
    "def get_openalex_publications(cursor, total_results_count):\n",
    "    print(f\"\\\"{cursor}\\\", {total_results_count}\")\n",
    "    r = requests.get(\n",
    "        f\"https://api.openalex.org/works?filter=institutions.country_code:FR,is_paratext:false,publication_year:2013-2021&per-page={OA_PAGE_SIZE}&api_key={OA_API_KEY}&cursor={cursor}\")\n",
    "    response = r.json()\n",
    "    results = response.get(\"results\")\n",
    "    actions = []\n",
    "    for publication in results:\n",
    "        open_alex_id = publication.get(\"id\")\n",
    "        doi = False\n",
    "        if publication.get(\"doi\"):\n",
    "            doi = publication.get(\"doi\", \"\").replace(\"https://doi.org/\", \"\")\n",
    "        hal_landing_page_urls = [location.get(\"landing_page_url\") for location in response.get(\"locations\", []) if re.match(\"^https:\\/\\/hal\\.(science|archives-ouvertes\\.fr|inria\\.fr)\\/(hal-\\d*)\", location.get(\"landing_page_url\", \"\"))]\n",
    "        hal_ids_uniq = list(set([hal_landing_page_url.split('/')[3] for hal_landing_page_url in hal_landing_page_urls]))\n",
    "        if len(hal_ids_uniq) > 1:\n",
    "            print(f\"More than one hal_id in OpenAlex work : {open_alex_id}\")\n",
    "            hal_id = False\n",
    "        else:\n",
    "            hal_id = hal_ids_uniq[0] if len(hal_ids_uniq) == 1 else False\n",
    "        id = doi if doi else hal_id if hal_id else open_alex_id\n",
    "        id = id.lower()\n",
    "        if id:\n",
    "            all_ids = [{\"id_type\": k, \"id_value\": v} for k, v in publication.get(\"ids\").items()]\n",
    "            if open_alex_id and len([id for id in all_ids if id.get(\"id_type\") == \"openalex\"]) == 0:\n",
    "                all_ids.append({\"id_type\": \"openalex\", \"id_value\": open_alex_id})\n",
    "            if doi and len([id for id in all_ids if id.get(\"id_type\") == \"doi\"]) == 0:\n",
    "                all_ids.append({\"id_type\": \"doi\", \"id_value\": doi})\n",
    "            if hal_id and len([id for id in all_ids if id.get(\"id_type\") == \"hal_id\"]) == 0:\n",
    "                all_ids.append({\"id_type\": \"hal_id\", \"id_value\": hal_id})\n",
    "            publication = {\n",
    "                \"all_ids\": all_ids,\n",
    "                \"id\": id,\n",
    "                \"is_in_openalex\": True,\n",
    "                \"openalex\": publication,\n",
    "            }\n",
    "            actions.append(pymongo.UpdateOne(\n",
    "                {\"id\": id}, {\"$set\": publication}, upsert=True))\n",
    "    if len(actions) > 0:\n",
    "        mongo_collection.bulk_write(actions, ordered=False)\n",
    "    results_count = len(results)\n",
    "    total_results_count += results_count\n",
    "    next_cursor = response.get(\"meta\").get(\"next_cursor\")\n",
    "    del actions\n",
    "    del r\n",
    "    del response\n",
    "    del results\n",
    "    print('{:.0f} %'.format((total_results_count / openalex_total_count) * 100))\n",
    "    if next_cursor is not None and results_count > 0 and (OA_LIMIT == 0 or len(total_results_count) < OA_LIMIT):\n",
    "        return get_openalex_publications(next_cursor, total_results_count)\n",
    "    else:\n",
    "        return total_results_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all French publications in OpenAlex\n",
    "openalex_publications = get_openalex_publications(\"*\", 0)\n",
    "print(openalex_publications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compute year field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set year with priority to FOSM\n",
    "publicationsCount = mongo_collection.count_documents({ \"year\": { \"$exists\": False } })\n",
    "publications = mongo_collection.find({ \"year\": { \"$exists\": False } })\n",
    "actions = []\n",
    "index = 0\n",
    "for publication in publications:\n",
    "  index += 1\n",
    "  year_fosm = publication.get(\"fosm\", {}).get(\"year\")\n",
    "  year_openalex = publication.get(\"openalex\", {}).get(\"publication_year\")\n",
    "  if year_fosm:\n",
    "    actions.append(pymongo.UpdateOne({ \"id\": publication.get(\"id\") }, { \"$set\": { \"year\": year_fosm } }, upsert=True))\n",
    "  elif year_openalex:\n",
    "    actions.append(pymongo.UpdateOne({ \"id\": publication.get(\"id\") }, { \"$set\": { \"year\": year_openalex } }, upsert=True))\n",
    "  if len(actions) == MONGO_CHUNK_SIZE:\n",
    "    print(f\"{index} / {publicationsCount}\")\n",
    "    mongo_collection.bulk_write(actions, ordered=False)\n",
    "    actions = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compute detected countries from OpenAlex raw_affiliation_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute detected countries on raw affiliations from OpenAlex\n",
    "publicationsCount = mongo_collection.count_documents({ \"is_in_openalex\": True, \"openalex_detected_countries\": { \"$exists\": False }, \"year\": 2021 })\n",
    "publications = mongo_collection.find({ \"is_in_openalex\": True, \"openalex_detected_countries\": { \"$exists\": False }, \"year\": 2021 })\n",
    "actions = []\n",
    "index = 0\n",
    "for publication in publications:\n",
    "  index += 1\n",
    "  institutions = [i.get(\"raw_affiliation_strings\", []) for i in publication.get(\"openalex\", {}).get(\"authorships\", [])]\n",
    "  institutions = [j for sub in institutions for j in sub]\n",
    "  institutions = list(set(institutions))\n",
    "  openalex_detected_countries = []\n",
    "  for institution in institutions:\n",
    "    r = requests.post(\"https://affiliation-matcher.staging.dataesr.ovh/match\", json={ \"type\": \"country\", \"year\": \"2022\", \"verbose\": True, \"query\": institution })\n",
    "    openalex_detected_countries += r.json().get(\"results\", [])\n",
    "  openalex_detected_countries = list(set(openalex_detected_countries))\n",
    "  actions.append(pymongo.UpdateOne({ \"id\": publication.get(\"id\") }, { \"$set\": { \"openalex_detected_countries\": openalex_detected_countries } }, upsert=True))\n",
    "  if len(actions) == MONGO_CHUNK_SIZE:\n",
    "    print(f\"{index} / {publicationsCount}\")\n",
    "    mongo_collection.bulk_write(actions, ordered=False)\n",
    "    actions = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
